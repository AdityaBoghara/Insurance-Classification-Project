{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a394fa",
   "metadata": {},
   "source": [
    "# Final Course Group Project – Insurance Purchase Prediction\n",
    "\n",
    "**Course:** BZAN 6357 – Business Analytics with Python  \n",
    "**Project Type:** Supervised ML (Classification)  \n",
    "**Template generated:** 2025-10-30\n",
    "\n",
    "## Team\n",
    "- Aditya Boghara \n",
    "- Meghana\n",
    "\n",
    "## Deliverables\n",
    "Submit a single zip with:  \n",
    "1) This notebook (fully executed).  \n",
    "2) `my_prediction.csv` with **exactly** 3 columns: `id_new`, `probability`, `classification`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce3064",
   "metadata": {},
   "source": [
    "## 1) Introduction & Objective\n",
    "- **Background:** Cross-sell *car insurance* to existing medical policyholders.\n",
    "- **Objective:** Predict purchase probability (1=purchased, 0=not purchased) and classify Score data.\n",
    "- **Evaluation:** AUC-ROC and F1 score on held-out test; clarity and rigor of this notebook.\n",
    "- **Approach (summary):** Data prep → EDA → Modeling (baseline → tuned) → Evaluation → Score file export."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc08fd9",
   "metadata": {},
   "source": [
    "## 2) Setup\n",
    "Fill in project constants and file paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0a86f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Project constants ===\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2  # 20% test split\n",
    "N_FOLDS = 5  # 5- or 10-fold CV recommended\n",
    "\n",
    "# File names expected by the project\n",
    "TRAIN_FILE = \"bzan6357_insurance_3_TRAINING.csv\"\n",
    "SCORE_FILE = \"bzan6357_insurance_3_SCORE.csv\"\n",
    "SUBMIT_FILE = \"my_prediction.csv\"  # must contain: id_new, probability, classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d3367",
   "metadata": {},
   "source": [
    "## 3) Imports\n",
    "Only add libraries you actually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd95ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f304c9",
   "metadata": {},
   "source": [
    "## 4) Data Load & Quick Audit\n",
    "If files are missing, you'll see a helpful message instead of a crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1747790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy\n",
      "0    16705\n",
      "1     3755\n",
      "Name: count, dtype: int64\n",
      "buy\n",
      "0    81.647116\n",
      "1    18.352884\n",
      "Name: proportion, dtype: float64\n",
      "Shape of df_train (20460, 12)\n",
      "Shape of df_score (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load data (paths are already set above)\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_score = pd.read_csv(SCORE_FILE)\n",
    "\n",
    "df_train.head()\n",
    "\n",
    "y = df_train[\"buy\"]\n",
    "\n",
    "print(y.value_counts())\n",
    "print(y.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"Shape of df_train\", df_train.shape)\n",
    "print(\"Shape of df_score\", df_score.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc063af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be43733d",
   "metadata": {},
   "source": [
    "## 5) Basic EDA (brief)\n",
    "Keep this concise and focused on modeling decisions.\n",
    "\n",
    "**Suggested checks:**\n",
    "- Target balance (`buy`).  \n",
    "- Distributions of numeric features (e.g., `age`, `tenure`, `v_prem_quote`).  \n",
    "- Cardinality of `region`, `cs_rep`.  \n",
    "- Categorical value ranges (`gender`, `v_age`, `v_accident`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e9d8f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'tenure', 'region', 'dl', 'has_v_insurance', 'v_prem_quote', 'cs_rep']\n",
      "['gender', 'v_age', 'v_accident']\n",
      "Shape of df_train (20460, 10)\n",
      "Shape of df_score (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Target and features\n",
    "y = df_train[\"buy\"].astype(int)\n",
    "X = df_train.drop(columns=[\"buy\"])\n",
    "\n",
    "\n",
    "X = X.drop(columns=[\"id_new\"])\n",
    "\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "\n",
    "print(numeric_features)\n",
    "print(categorical_features)\n",
    "\n",
    "\n",
    "score_ids = df_score[\"id_new\"].copy()\n",
    "X_score = df_score.drop(columns=[\"id_new\"])\n",
    "\n",
    "numeric_features = [c for c in X.select_dtypes(include=[\"int64\", \"float64\"]).columns]\n",
    "categorical_features = [\n",
    "    c for c in X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"OneHotEncoder\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
    "        (\"StandardScaler\", StandardScaler(with_mean=False), numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Shape of df_train\", X.shape)\n",
    "print(\"Shape of df_score\", X_score.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b00ba",
   "metadata": {},
   "source": [
    "## 6) Preprocessing (Pipelines)\n",
    "Use a **ColumnTransformer** so the *same* steps can be reused for TEST and SCORE.\n",
    "\n",
    "**Notes:**\n",
    "- Treat high-cardinality IDs (e.g., `region`, `cs_rep`) with One-Hot (can be large) or try frequency encoding.\n",
    "- One-Hot encode: `gender`, `v_age`, `v_accident`, `region`, `cs_rep`.\n",
    "- Scale numeric features as needed for certain models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae4ddc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 1.39816747,\n",
       "        9.7316272 ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 2.3758078 ,\n",
       "        9.19429809],\n",
       "       [1.        , 0.        , 0.        , ..., 2.23570222, 1.64180453,\n",
       "        7.28379459],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.        , ..., 2.23570222, 3.62885928,\n",
       "        7.28379459],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 1.95069579,\n",
       "        7.28379459],\n",
       "       [1.        , 0.        , 1.        , ..., 0.        , 2.10455499,\n",
       "        7.28379459]], shape=(2000, 11))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessor.fit_transform(X)\n",
    "X_score = preprocessor.transform(X_score)\n",
    "\n",
    "X_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fba3be",
   "metadata": {},
   "source": [
    "## 7) Train/Test Split\n",
    "Stratify on `buy` to preserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07c56b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de0de910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: (16368, 11) (16368,)\n",
      "After SMOTE: (26786, 11) (26786,)\n",
      "value count before SMOTE: buy\n",
      "0    13393\n",
      "1     2975\n",
      "Name: count, dtype: int64\n",
      "value count After SMOTE: buy\n",
      "0    13393\n",
      "1    13393\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 2. Apply SMOTE only on the training set\n",
    "sm = SMOTE(random_state=42)\n",
    "X_tr_res, y_tr_res = sm.fit_resample(X_tr, y_tr)\n",
    "\n",
    "\n",
    "print(\"Before SMOTE:\", X_tr.shape, y_tr.shape)\n",
    "print(\"After SMOTE:\", X_tr_res.shape, y_tr_res.shape)\n",
    "\n",
    "print(\"value count before SMOTE:\", y_tr.value_counts())\n",
    "print(\"value count After SMOTE:\", y_tr_res.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f192455",
   "metadata": {},
   "source": [
    "## 8) Baseline Models\n",
    "Start with a few solid baselines and compare AUC/F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954dca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential( input_dim: int, lr: float = 1e-3, dropout: float = 0.2) -> tf.keras.Model:\n",
    "    \"\"\"Binary-classification MLP in pure tf.keras Sequential.\"\"\"\n",
    "    model = Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout / 2),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "            tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e1128",
   "metadata": {},
   "source": [
    "Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b02bc303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6855 - auc: 0.7288 - loss: 0.5882 - val_accuracy: 0.8096 - val_auc: 0.7395 - val_loss: 0.5644\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7059 - auc: 0.7564 - loss: 0.5444 - val_accuracy: 0.8079 - val_auc: 0.7345 - val_loss: 0.5154\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7137 - auc: 0.7634 - loss: 0.5361 - val_accuracy: 0.5565 - val_auc: 0.7359 - val_loss: 0.6033\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7164 - auc: 0.7687 - loss: 0.5298 - val_accuracy: 0.5061 - val_auc: 0.7372 - val_loss: 0.6608\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7192 - auc: 0.7740 - loss: 0.5253 - val_accuracy: 0.5227 - val_auc: 0.7498 - val_loss: 0.6534\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7234 - auc: 0.7752 - loss: 0.5237 - val_accuracy: 0.5557 - val_auc: 0.7596 - val_loss: 0.6147\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7283 - auc: 0.7795 - loss: 0.5192 - val_accuracy: 0.5699 - val_auc: 0.7500 - val_loss: 0.5992\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7272 - auc: 0.7784 - loss: 0.5209 - val_accuracy: 0.5670 - val_auc: 0.7613 - val_loss: 0.6007\n",
      "Epoch 9/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7284 - auc: 0.7822 - loss: 0.5165 - val_accuracy: 0.5794 - val_auc: 0.7592 - val_loss: 0.5865\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7297 - auc: 0.7835 - loss: 0.5156 - val_accuracy: 0.6263 - val_auc: 0.7647 - val_loss: 0.5568\n",
      "Epoch 11/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7293 - auc: 0.7847 - loss: 0.5145 - val_accuracy: 0.5956 - val_auc: 0.7636 - val_loss: 0.5874\n",
      "Epoch 12/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7293 - auc: 0.7841 - loss: 0.5150 - val_accuracy: 0.6078 - val_auc: 0.7674 - val_loss: 0.5868\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step\n",
      "\n",
      "Validation AUC: 0.7349\n",
      "Best threshold (F1): 0.4051\n",
      "Validation F1: 0.4411\n",
      "Confusion Matrix (val):\n",
      " [[1943 1369]\n",
      " [ 172  608]]\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9187    0.5867    0.7160      3312\n",
      "           1     0.3075    0.7795    0.4411       780\n",
      "\n",
      "    accuracy                         0.6234      4092\n",
      "   macro avg     0.6131    0.6831    0.5786      4092\n",
      "weighted avg     0.8022    0.6234    0.6636      4092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_sequential(input_dim=X_tr_res.shape[1], lr=1e-3, dropout=0.2)\n",
    "hist = model.fit(\n",
    "    X_tr_res,\n",
    "    y_tr_res,\n",
    "    validation_data=(X_va, y_va),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "proba_va = model.predict(X_va).ravel()\n",
    "prec, rec, thr = precision_recall_curve(y_va, proba_va)\n",
    "f1_vals = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = int(np.nanargmax(f1_vals))\n",
    "best_thr = float(thr[max(best_idx - 1, 0)]) if best_idx < len(thr) else 0.5\n",
    "\n",
    "\n",
    "pred_va = (proba_va >= best_thr).astype(int)\n",
    "print(f\"\\nValidation AUC: {roc_auc_score(y_va, proba_va):.4f}\")\n",
    "print(f\"Best threshold (F1): {best_thr:.4f}\")\n",
    "print(f\"Validation F1: {f1_score(y_va, pred_va):.4f}\")\n",
    "print(\"Confusion Matrix (val):\\n\", confusion_matrix(y_va, pred_va))\n",
    "print(\n",
    "    \"\\nClassification Report (val):\\n\", classification_report(y_va, pred_va, digits=4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f2210",
   "metadata": {},
   "source": [
    "Using Class Weights!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d43dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61106548 2.75092437]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_tr),\n",
    "    y=y_tr\n",
    ")\n",
    "\n",
    "print(class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad766eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6110654819681923, 1: 1.9256470588235295}\n",
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5672 - auc: 0.6917 - loss: 0.5668 - val_accuracy: 0.5281 - val_auc: 0.7138 - val_loss: 0.6701\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6114 - auc: 0.7298 - loss: 0.5046 - val_accuracy: 0.6029 - val_auc: 0.6902 - val_loss: 0.6130\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6332 - auc: 0.7418 - loss: 0.4826 - val_accuracy: 0.7520 - val_auc: 0.7148 - val_loss: 0.5490\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6529 - auc: 0.7508 - loss: 0.4719 - val_accuracy: 0.7571 - val_auc: 0.7491 - val_loss: 0.5343\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6568 - auc: 0.7484 - loss: 0.4701 - val_accuracy: 0.7036 - val_auc: 0.7476 - val_loss: 0.5325\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6628 - auc: 0.7538 - loss: 0.4663 - val_accuracy: 0.7532 - val_auc: 0.7448 - val_loss: 0.4889\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6603 - auc: 0.7502 - loss: 0.4634 - val_accuracy: 0.6852 - val_auc: 0.7450 - val_loss: 0.5066\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Validation AUC: 0.6903\n",
      "Validation F1: 0.0000\n",
      "Confusion Matrix (val):\n",
      " [[3312    0]\n",
      " [ 780    0]]\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8094    1.0000    0.8947      3312\n",
      "           1     0.0000    0.0000    0.0000       780\n",
      "\n",
      "    accuracy                         0.8094      4092\n",
      "   macro avg     0.4047    0.5000    0.4473      4092\n",
      "weighted avg     0.6551    0.8094    0.7241      4092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaboghara/Desktop/UH MIS/FALL 2025/BZAN 6357/Assignments/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/adityaboghara/Desktop/UH MIS/FALL 2025/BZAN 6357/Assignments/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/adityaboghara/Desktop/UH MIS/FALL 2025/BZAN 6357/Assignments/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_tr)\n",
    "w = compute_class_weight('balanced', classes=classes, y=y_tr)\n",
    "scale_pos = 0.7 \n",
    "cw_soft = {int(c): (float(w[i]) * (scale_pos if c==1 else 1.0))\n",
    "           for i, c in enumerate(classes)}\n",
    "\n",
    "\n",
    "\n",
    "print(cw_soft)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_auc', mode='min',\n",
    "                                        patience=5, restore_best_weights=True)\n",
    "\n",
    "model1 = build_sequential(input_dim=X_tr.shape[1], lr=1e-3, dropout=0.2)\n",
    "hist = model1.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    validation_data=(X_va, y_va),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    verbose=1, \n",
    "    class_weight = cw_soft\n",
    ")\n",
    "\n",
    "\n",
    "proba_va = model1.predict(X_va).ravel()\n",
    "prec, rec, thr = precision_recall_curve(y_va, proba_va)\n",
    "f1_vals = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "\n",
    "\n",
    "pred_va = (proba_va >= 0.7).astype(int)\n",
    "print(f\"\\nValidation AUC: {roc_auc_score(y_va, proba_va):.4f}\")\n",
    "print(f\"Validation F1: {f1_score(y_va, pred_va):.4f}\")\n",
    "print(\"Confusion Matrix (val):\\n\", confusion_matrix(y_va, pred_va))\n",
    "print(\n",
    "    \"\\nClassification Report (val):\\n\", classification_report(y_va, pred_va, digits=4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ed6fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step\n",
      "\n",
      "Validation AUC: 0.6920\n",
      "Validation F1: 0.0000\n",
      "Confusion Matrix (val):\n",
      " [[16705     0]\n",
      " [ 3755     0]]\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8165    1.0000    0.8990     16705\n",
      "           1     0.0000    0.0000    0.0000      3755\n",
      "\n",
      "    accuracy                         0.8165     20460\n",
      "   macro avg     0.4082    0.5000    0.4495     20460\n",
      "weighted avg     0.6666    0.8165    0.7340     20460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaboghara/Desktop/UH MIS/FALL 2025/BZAN 6357/Assignments/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/adityaboghara/Desktop/UH MIS/FALL 2025/BZAN 6357/Assignments/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/adityaboghara/Desktop/UH MIS/FALL 2025/BZAN 6357/Assignments/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "proba_va = model1.predict(X).ravel()\n",
    "prec, rec, thr = precision_recall_curve(y, proba_va)\n",
    "f1_vals = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "\n",
    "\n",
    "pred_va = (proba_va >= 0.7).astype(int)\n",
    "print(f\"\\nValidation AUC: {roc_auc_score(y, proba_va):.4f}\")\n",
    "print(f\"Validation F1: {f1_score(y, pred_va):.4f}\")\n",
    "print(\"Confusion Matrix (val):\\n\", confusion_matrix(y, pred_va))\n",
    "print(\n",
    "    \"\\nClassification Report (val):\\n\", classification_report(y, pred_va, digits=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce15466",
   "metadata": {},
   "source": [
    "## 9) Model Selection & (Optional) Hyperparameter Tuning\n",
    "Pick the best baseline by AUC/F1, then optionally run a small grid search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206885ad",
   "metadata": {},
   "source": [
    "## 10) Fit Final Model on Full Training Set\n",
    "Use the chosen/tuned pipeline and refit on the entire TRAIN set (`X`, `y`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ff645",
   "metadata": {},
   "source": [
    "## 11) Score Dataset → Create `my_prediction.csv`\n",
    "Follow the required format: `id_new`, `probability` (for class 1 only), `classification` (argmax)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5c983",
   "metadata": {},
   "source": [
    "## 12) Results, Interpretation, and Recommendations\n",
    "**Summarize:**\n",
    "- Best model and *why* it was chosen.\n",
    "- AUC/F1 on the test set and what that implies.\n",
    "- Any key drivers of purchase you identified.\n",
    "- Business recommendations (who to target, how to use scores, next steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77dcadd",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "- Python/Sklearn versions\n",
    "- Reproducibility notes\n",
    "- Any references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e506adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:07:49) [Clang 20.1.8 ]\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.4\n",
      "sklearn: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "import sys, sklearn\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13261fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
