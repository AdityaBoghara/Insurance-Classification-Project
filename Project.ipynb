{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a394fa",
   "metadata": {},
   "source": [
    "# Final Course Group Project – Insurance Purchase Prediction\n",
    "\n",
    "**Course:** BZAN 6357 – Business Analytics with Python  \n",
    "**Project Type:** Supervised ML (Classification)  \n",
    "**Template generated:** 2025-10-30\n",
    "\n",
    "## Team\n",
    "- Aditya Boghara \n",
    "- Meghana\n",
    "\n",
    "## Deliverables\n",
    "Submit a single zip with:  \n",
    "1) This notebook (fully executed).  \n",
    "2) `my_prediction.csv` with **exactly** 3 columns: `id_new`, `probability`, `classification`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce3064",
   "metadata": {},
   "source": [
    "## 1) Introduction & Objective\n",
    "- **Background:** Cross-sell *car insurance* to existing medical policyholders.\n",
    "- **Objective:** Predict purchase probability (1=purchased, 0=not purchased) and classify Score data.\n",
    "- **Evaluation:** AUC-ROC and F1 score on held-out test; clarity and rigor of this notebook.\n",
    "- **Approach (summary):** Data prep → EDA → Modeling (baseline → tuned) → Evaluation → Score file export."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc08fd9",
   "metadata": {},
   "source": [
    "## 2) Setup\n",
    "Fill in project constants and file paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0a86f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Project constants ===\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2  # 20% test split\n",
    "N_FOLDS = 5  # 5- or 10-fold CV recommended\n",
    "\n",
    "# File names expected by the project\n",
    "TRAIN_FILE = \"bzan6357_insurance_3_TRAINING.csv\"\n",
    "SCORE_FILE = \"bzan6357_insurance_3_SCORE.csv\"\n",
    "SUBMIT_FILE = \"my_prediction.csv\"  # must contain: id_new, probability, classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d3367",
   "metadata": {},
   "source": [
    "## 3) Imports\n",
    "Only add libraries you actually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd95ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f304c9",
   "metadata": {},
   "source": [
    "## 4) Data Load & Quick Audit\n",
    "If files are missing, you'll see a helpful message instead of a crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1747790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy\n",
      "0    16705\n",
      "1     3755\n",
      "Name: count, dtype: int64\n",
      "buy\n",
      "0    81.647116\n",
      "1    18.352884\n",
      "Name: proportion, dtype: float64\n",
      "Shape of df_train (20460, 12)\n",
      "Shape of df_score (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load data (paths are already set above)\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_score = pd.read_csv(SCORE_FILE)\n",
    "\n",
    "df_train.head()\n",
    "\n",
    "y = df_train[\"buy\"]\n",
    "\n",
    "print(y.value_counts())\n",
    "print(y.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"Shape of df_train\", df_train.shape)\n",
    "print(\"Shape of df_score\", df_score.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc063af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be43733d",
   "metadata": {},
   "source": [
    "## 5) Basic EDA (brief)\n",
    "Keep this concise and focused on modeling decisions.\n",
    "\n",
    "**Suggested checks:**\n",
    "- Target balance (`buy`).  \n",
    "- Distributions of numeric features (e.g., `age`, `tenure`, `v_prem_quote`).  \n",
    "- Cardinality of `region`, `cs_rep`.  \n",
    "- Categorical value ranges (`gender`, `v_age`, `v_accident`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e9d8f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'tenure', 'region', 'dl', 'has_v_insurance', 'v_prem_quote', 'cs_rep']\n",
      "['gender', 'v_age', 'v_accident']\n",
      "Shape of df_train (20460, 10)\n",
      "Shape of df_score (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Target and features\n",
    "y = df_train[\"buy\"].astype(int)\n",
    "X = df_train.drop(columns=[\"buy\"])\n",
    "\n",
    "\n",
    "X = X.drop(columns=[\"id_new\"])\n",
    "\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "\n",
    "print(numeric_features)\n",
    "print(categorical_features)\n",
    "\n",
    "\n",
    "score_ids = df_score[\"id_new\"].copy()\n",
    "X_score = df_score.drop(columns=[\"id_new\"])\n",
    "\n",
    "numeric_features = [c for c in X.select_dtypes(include=[\"int64\", \"float64\"]).columns]\n",
    "categorical_features = [\n",
    "    c for c in X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"OneHotEncoder\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
    "        (\"StandardScaler\", StandardScaler(with_mean=False), numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Shape of df_train\", X.shape)\n",
    "print(\"Shape of df_score\", X_score.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b00ba",
   "metadata": {},
   "source": [
    "## 6) Preprocessing (Pipelines)\n",
    "Use a **ColumnTransformer** so the *same* steps can be reused for TEST and SCORE.\n",
    "\n",
    "**Notes:**\n",
    "- Treat high-cardinality IDs (e.g., `region`, `cs_rep`) with One-Hot (can be large) or try frequency encoding.\n",
    "- One-Hot encode: `gender`, `v_age`, `v_accident`, `region`, `cs_rep`.\n",
    "- Scale numeric features as needed for certain models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae4ddc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 1.39816747,\n",
       "        9.7316272 ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 2.3758078 ,\n",
       "        9.19429809],\n",
       "       [1.        , 0.        , 0.        , ..., 2.23570222, 1.64180453,\n",
       "        7.28379459],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.        , ..., 2.23570222, 3.62885928,\n",
       "        7.28379459],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 1.95069579,\n",
       "        7.28379459],\n",
       "       [1.        , 0.        , 1.        , ..., 0.        , 2.10455499,\n",
       "        7.28379459]], shape=(2000, 11))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessor.fit_transform(X)\n",
    "X_score = preprocessor.transform(X_score)\n",
    "\n",
    "X_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fba3be",
   "metadata": {},
   "source": [
    "## 7) Train/Test Split\n",
    "Stratify on `buy` to preserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07c56b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de0de910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: (16368, 11) (16368,)\n",
      "After SMOTE: (26786, 11) (26786,)\n",
      "value count before SMOTE: buy\n",
      "0    13393\n",
      "1     2975\n",
      "Name: count, dtype: int64\n",
      "value count After SMOTE: buy\n",
      "0    13393\n",
      "1    13393\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 2. Apply SMOTE only on the training set\n",
    "sm = SMOTE(random_state=42)\n",
    "X_tr_res, y_tr_res = sm.fit_resample(X_tr, y_tr)\n",
    "\n",
    "\n",
    "print(\"Before SMOTE:\", X_tr.shape, y_tr.shape)\n",
    "print(\"After SMOTE:\", X_tr_res.shape, y_tr_res.shape)\n",
    "\n",
    "print(\"value count before SMOTE:\", y_tr.value_counts())\n",
    "print(\"value count After SMOTE:\", y_tr_res.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f192455",
   "metadata": {},
   "source": [
    "## 8) Baseline Models\n",
    "Start with a few solid baselines and compare AUC/F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "954dca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential( input_dim: int, lr: float = 1e-3, dropout: float = 0.2) -> tf.keras.Model:\n",
    "    \"\"\"Binary-classification MLP in pure tf.keras Sequential.\"\"\"\n",
    "    model = Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout / 2),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "            tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e1128",
   "metadata": {},
   "source": [
    "Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b02bc303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6861 - auc: 0.7317 - loss: 0.5848 - val_accuracy: 0.7637 - val_auc: 0.7065 - val_loss: 0.5630\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7095 - auc: 0.7597 - loss: 0.5413 - val_accuracy: 0.5472 - val_auc: 0.7232 - val_loss: 0.6140\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7146 - auc: 0.7652 - loss: 0.5340 - val_accuracy: 0.5459 - val_auc: 0.7393 - val_loss: 0.6258\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7194 - auc: 0.7726 - loss: 0.5280 - val_accuracy: 0.5393 - val_auc: 0.7479 - val_loss: 0.6238\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7221 - auc: 0.7753 - loss: 0.5240 - val_accuracy: 0.5574 - val_auc: 0.7440 - val_loss: 0.6233\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7221 - auc: 0.7754 - loss: 0.5230 - val_accuracy: 0.5682 - val_auc: 0.7501 - val_loss: 0.5977\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7279 - auc: 0.7770 - loss: 0.5213 - val_accuracy: 0.5975 - val_auc: 0.7488 - val_loss: 0.5596\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7263 - auc: 0.7811 - loss: 0.5186 - val_accuracy: 0.5797 - val_auc: 0.7629 - val_loss: 0.5663\n",
      "Epoch 9/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7293 - auc: 0.7814 - loss: 0.5178 - val_accuracy: 0.6244 - val_auc: 0.7653 - val_loss: 0.5455\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7286 - auc: 0.7841 - loss: 0.5158 - val_accuracy: 0.6151 - val_auc: 0.7689 - val_loss: 0.5590\n",
      "Epoch 11/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7305 - auc: 0.7836 - loss: 0.5151 - val_accuracy: 0.6491 - val_auc: 0.7608 - val_loss: 0.5171\n",
      "Epoch 12/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7337 - auc: 0.7859 - loss: 0.5140 - val_accuracy: 0.6095 - val_auc: 0.7669 - val_loss: 0.5629\n",
      "Epoch 13/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7305 - auc: 0.7841 - loss: 0.5142 - val_accuracy: 0.6303 - val_auc: 0.7683 - val_loss: 0.5499\n",
      "Epoch 14/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7318 - auc: 0.7871 - loss: 0.5124 - val_accuracy: 0.5902 - val_auc: 0.7562 - val_loss: 0.5813\n",
      "Epoch 15/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7336 - auc: 0.7869 - loss: 0.5118 - val_accuracy: 0.6073 - val_auc: 0.7686 - val_loss: 0.5664\n",
      "Epoch 16/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7335 - auc: 0.7861 - loss: 0.5125 - val_accuracy: 0.5982 - val_auc: 0.7579 - val_loss: 0.5722\n",
      "Epoch 17/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7350 - auc: 0.7885 - loss: 0.5102 - val_accuracy: 0.5973 - val_auc: 0.7625 - val_loss: 0.5794\n",
      "Epoch 18/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7344 - auc: 0.7889 - loss: 0.5103 - val_accuracy: 0.6317 - val_auc: 0.7684 - val_loss: 0.5385\n",
      "Epoch 19/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7356 - auc: 0.7905 - loss: 0.5084 - val_accuracy: 0.6131 - val_auc: 0.7604 - val_loss: 0.5509\n",
      "Epoch 20/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - auc: 0.7897 - loss: 0.5089 - val_accuracy: 0.6097 - val_auc: 0.7557 - val_loss: 0.5647\n",
      "Epoch 21/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7370 - auc: 0.7904 - loss: 0.5076 - val_accuracy: 0.6408 - val_auc: 0.7672 - val_loss: 0.5348\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n",
      "\n",
      "Validation AUC: 0.7610\n",
      "Best threshold (F1): 0.5370\n",
      "Validation F1: 0.4597\n",
      "Confusion Matrix (val):\n",
      " [[2189 1123]\n",
      " [ 212  568]]\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9117    0.6609    0.7663      3312\n",
      "           1     0.3359    0.7282    0.4597       780\n",
      "\n",
      "    accuracy                         0.6738      4092\n",
      "   macro avg     0.6238    0.6946    0.6130      4092\n",
      "weighted avg     0.8019    0.6738    0.7079      4092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_sequential(input_dim=X_tr_res.shape[1], lr=1e-3, dropout=0.2)\n",
    "hist = model.fit(\n",
    "    X_tr_res,\n",
    "    y_tr_res,\n",
    "    validation_data=(X_va, y_va),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "proba_va = model.predict(X_va).ravel()\n",
    "prec, rec, thr = precision_recall_curve(y_va, proba_va)\n",
    "f1_vals = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = int(np.nanargmax(f1_vals))\n",
    "best_thr = float(thr[max(best_idx - 1, 0)]) if best_idx < len(thr) else 0.5\n",
    "\n",
    "\n",
    "pred_va = (proba_va >= best_thr).astype(int)\n",
    "print(f\"\\nValidation AUC: {roc_auc_score(y_va, proba_va):.4f}\")\n",
    "print(f\"Best threshold (F1): {best_thr:.4f}\")\n",
    "print(f\"Validation F1: {f1_score(y_va, pred_va):.4f}\")\n",
    "print(\"Confusion Matrix (val):\\n\", confusion_matrix(y_va, pred_va))\n",
    "print(\n",
    "    \"\\nClassification Report (val):\\n\", classification_report(y_va, pred_va, digits=4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f2210",
   "metadata": {},
   "source": [
    "Using Class Weights!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d43dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61106548 2.75092437]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_tr),\n",
    "    y=y_tr\n",
    ")\n",
    "\n",
    "print(class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad766eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6110654819681923, 1: 1.9256470588235295}\n",
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5733 - auc: 0.6860 - loss: 0.5811 - val_accuracy: 0.7766 - val_auc: 0.6931 - val_loss: 0.6012\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6206 - auc: 0.7288 - loss: 0.5071 - val_accuracy: 0.8089 - val_auc: 0.6934 - val_loss: 0.5459\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6405 - auc: 0.7363 - loss: 0.4897 - val_accuracy: 0.7287 - val_auc: 0.6978 - val_loss: 0.5797\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6525 - auc: 0.7379 - loss: 0.4806 - val_accuracy: 0.7199 - val_auc: 0.7063 - val_loss: 0.5510\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6615 - auc: 0.7483 - loss: 0.4709 - val_accuracy: 0.7495 - val_auc: 0.7167 - val_loss: 0.5144\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6617 - auc: 0.7510 - loss: 0.4676 - val_accuracy: 0.7370 - val_auc: 0.7289 - val_loss: 0.5016\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n",
      "\n",
      "Validation AUC: 0.6932\n",
      "Validation F1: 0.1825\n",
      "Confusion Matrix (val):\n",
      " [[3076  236]\n",
      " [ 678  102]]\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8194    0.9287    0.8706      3312\n",
      "           1     0.3018    0.1308    0.1825       780\n",
      "\n",
      "    accuracy                         0.7766      4092\n",
      "   macro avg     0.5606    0.5298    0.5266      4092\n",
      "weighted avg     0.7207    0.7766    0.7395      4092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_tr)\n",
    "w = compute_class_weight('balanced', classes=classes, y=y_tr)\n",
    "scale_pos = 0.7 \n",
    "cw_soft = {int(c): (float(w[i]) * (scale_pos if c==1 else 1.0))\n",
    "           for i, c in enumerate(classes)}\n",
    "\n",
    "\n",
    "\n",
    "print(cw_soft)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_auc', mode='min',\n",
    "                                        patience=5, restore_best_weights=True)\n",
    "\n",
    "model1 = build_sequential(input_dim=X_tr.shape[1], lr=1e-3, dropout=0.2)\n",
    "hist = model1.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    validation_data=(X_va, y_va),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    verbose=1, \n",
    "    class_weight = cw_soft\n",
    ")\n",
    "\n",
    "\n",
    "proba_va = model1.predict(X_va).ravel()\n",
    "prec, rec, thr = precision_recall_curve(y_va, proba_va)\n",
    "f1_vals = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "\n",
    "\n",
    "pred_va = (proba_va >= 0.5).astype(int)\n",
    "print(f\"\\nValidation AUC: {roc_auc_score(y_va, proba_va):.4f}\")\n",
    "print(f\"Validation F1: {f1_score(y_va, pred_va):.4f}\")\n",
    "print(\"Confusion Matrix (val):\\n\", confusion_matrix(y_va, pred_va))\n",
    "print(\n",
    "    \"\\nClassification Report (val):\\n\", classification_report(y_va, pred_va, digits=4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ed6fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step\n",
      "[0 0 1 ... 0 0 0]\n",
      "\n",
      "Validation AUC: 0.7023\n",
      "Validation F1: 0.1803\n",
      "Confusion Matrix (val):\n",
      " [[15556  1149]\n",
      " [ 3269   486]]\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8263    0.9312    0.8757     16705\n",
      "           1     0.2972    0.1294    0.1803      3755\n",
      "\n",
      "    accuracy                         0.7841     20460\n",
      "   macro avg     0.5618    0.5303    0.5280     20460\n",
      "weighted avg     0.7292    0.7841    0.7480     20460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proba_va = model1.predict(X).ravel()\n",
    "prec, rec, thr = precision_recall_curve(y, proba_va)\n",
    "f1_vals = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "\n",
    "\n",
    "pred_va = (proba_va >= 0.5).astype(int)\n",
    "print(pred_va)\n",
    "print(f\"\\nValidation AUC: {roc_auc_score(y, proba_va):.4f}\")\n",
    "print(f\"Validation F1: {f1_score(y, pred_va):.4f}\")\n",
    "print(\"Confusion Matrix (val):\\n\", confusion_matrix(y, pred_va))\n",
    "print(\n",
    "    \"\\nClassification Report (val):\\n\", classification_report(y, pred_va, digits=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce15466",
   "metadata": {},
   "source": [
    "## 9) Model Selection & (Optional) Hyperparameter Tuning\n",
    "Pick the best baseline by AUC/F1, then optionally run a small grid search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206885ad",
   "metadata": {},
   "source": [
    "## 10) Fit Final Model on Full Training Set\n",
    "Use the chosen/tuned pipeline and refit on the entire TRAIN set (`X`, `y`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ff645",
   "metadata": {},
   "source": [
    "## 11) Score Dataset → Create `my_prediction.csv`\n",
    "Follow the required format: `id_new`, `probability` (for class 1 only), `classification` (argmax)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5c983",
   "metadata": {},
   "source": [
    "## 12) Results, Interpretation, and Recommendations\n",
    "**Summarize:**\n",
    "- Best model and *why* it was chosen.\n",
    "- AUC/F1 on the test set and what that implies.\n",
    "- Any key drivers of purchase you identified.\n",
    "- Business recommendations (who to target, how to use scores, next steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77dcadd",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "- Python/Sklearn versions\n",
    "- Reproducibility notes\n",
    "- Any references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e506adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:07:49) [Clang 20.1.8 ]\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.4\n",
      "sklearn: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "import sys, sklearn\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13261fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
